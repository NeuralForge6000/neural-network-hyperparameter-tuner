{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954acc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import the data\n",
    "data = pd.read_csv(r\"mnist.csv\")# Import the data\n",
    "\n",
    "# Calling head will show the first 5 rows of the dataset\n",
    "data.head()\n",
    "\n",
    "# Work with numpy arrays and not pandas\n",
    "data = np.array(data)\n",
    "# Get the dimensions of the data. m is the amount of rows and n is the amount of columns\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Split the data into training and testing data. .T is transpose, which is flipping the data, so each column is a row\n",
    "# data_dev is the data we will use to test our model\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "\n",
    "# data_train is the data we will use to train our model\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "\n",
    "# Normalize pixel values to 0-1 range for better training\n",
    "X_train = X_train / 255.0\n",
    "X_dev = X_dev / 255.0\n",
    "\n",
    "# Initialize parameters\n",
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# ReLU activation function. X if x > 0 and 0 if x <= 0\n",
    "def ReLU(Z):\n",
    "    # This will go through each element of the array and if it is greater than 0, it will keep it. If it is less than 0, it will make it 0\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "# Softmax activation function. This will take the exponential of each element in the array and then divide it by the sum of the exponential of each element in the array\n",
    "def softmax(Z):\n",
    "    # Numerically stable softmax\n",
    "    A = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    return A / np.sum(A, axis=0, keepdims=True)\n",
    "\n",
    "# Defining forward propagation\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)  # Fixed: was ReLU(Z) instead of ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# Defining one hot encoding, which is a way to represent categorical data as a vector of numbers\n",
    "def one_hot(Y):\n",
    "    # This will create a matrix of zeros with the same size as Y. Then it will go through each element of Y and make the corresponding element in the matrix 1\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    # This will go through each element of Y and make the corresponding element in the matrix 1\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    # This will transpose or flip the matrix so that it is the same size as Y\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "# Defining ReLU derivative. This will return 1 if the element is greater than 0 and 0 if it is less than 0\n",
    "def deriv_ReLU(Z):\n",
    "    return Z > 0\n",
    "\n",
    "# Defining backward propagation\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims=True)  # Fixed: sum along axis 1, keep dims\n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)  # Fixed: use deriv_ReLU function\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims=True)  # Fixed: sum along axis 1, keep dims\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# Defining update parameters\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Get predictions - returns the index of the highest value in the array\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "# Get accuracy\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "# Defining gradient descent\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        # Print the accuracy every 10 iterations\n",
    "        if i % 10 == 0:\n",
    "            # Calculate accuracy as the percentage of correct predictions out of total predictions\n",
    "            accuracy = get_accuracy(get_predictions(A2), Y)\n",
    "            print(f\"Iteration: {i}\")\n",
    "            # Display accuracy as both decimal (0.0-1.0) and percentage (0%-100%) for clarity\n",
    "            print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Train the model with proper learning rate\n",
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.5, 500)\n",
    "\n",
    "# Test on validation set\n",
    "Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_dev)\n",
    "dev_predictions = get_predictions(A2)\n",
    "dev_accuracy = get_accuracy(dev_predictions, Y_dev)\n",
    "print(f\"Validation Accuracy: {dev_accuracy:.4f} ({dev_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Visualization function to see predictions\n",
    "def show_prediction(index):\n",
    "    # Fashion-MNIST class names\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    \n",
    "    # Get the image and reshape it to 28x28\n",
    "    current_image = X_dev[:, index].reshape((28, 28))\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction_input = X_dev[:, index, None]  # Add dimension for prediction\n",
    "    Z1_pred, A1_pred, Z2_pred, A2_pred = forward_prop(W1, b1, W2, b2, prediction_input)\n",
    "    prediction = get_predictions(A2_pred)[0]\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(current_image, cmap='gray')\n",
    "    plt.title(f'Actual: {class_names[Y_dev[index]]}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(current_image, cmap='gray')\n",
    "    plt.title(f'Predicted: {class_names[prediction]}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show if prediction is correct\n",
    "    correct = \"✓\" if prediction == Y_dev[index] else \"✗\"\n",
    "    plt.suptitle(f'Prediction {correct}', fontsize=16, color='green' if correct == \"✓\" else 'red')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Actual: {class_names[Y_dev[index]]}, Predicted: {class_names[prediction]}\")\n",
    "\n",
    "# Show a few examples\n",
    "print(\"Showing Fashion-MNIST predictions:\")\n",
    "for i in range(10):\n",
    "    show_prediction(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
